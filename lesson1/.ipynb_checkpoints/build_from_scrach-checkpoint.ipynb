{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从头开始构建vgg\n",
    "本文目的是根据Keras来构建下vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhuanxu/PycharmProjects/udacity/fast-ai/lesson1/../data/redux\n",
      "/Users/zhuanxu/PycharmProjects/udacity/fast-ai/lesson1\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "current_directory = os.getcwd()\n",
    "LESSON_HOME_DIR = current_directory\n",
    "DATA_HOME_DIR = os.path.join(current_directory,\"../data/redux\")\n",
    "print(DATA_HOME_DIR)\n",
    "print(LESSON_HOME_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda,Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the VGG model.\n",
    "\n",
    "        Args: \n",
    "            x: Image array (height x width x channels)\n",
    "        Returns:\n",
    "            Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vgg_mean.shape,vgg_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始是Vgg16的模型\n",
    "![](vgg16_original.png)\n",
    "\n",
    "通过5个卷积层提取出特征，然后再通过一个全连接做分类，下面我们开始构建的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K.image_data_format())\n",
    "print(K.image_dim_ordering()) # image_dim_ordering 和 image_data_format 是一致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.set_image_data_format(\"channels_last\")\n",
    "# K.set_image_dim_ordering(\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(model, layers, filters):\n",
    "    \"\"\"\n",
    "        Adds a specified number of ZeroPadding and Covolution layers\n",
    "        to the model, and a MaxPooling layer at the very end.\n",
    "\n",
    "        Args:\n",
    "            layers (int):   The number of zero padded convolution layers\n",
    "                            to be added to the model.\n",
    "            filters (int):  The number of convolution filters to be \n",
    "                            created for each layer.\n",
    "    \"\"\"\n",
    "    for i in range(layers):\n",
    "        # the dimensionality of the output space\n",
    "        model.add(Conv2D(filters,kernel_size=(3,3))) # padding='valid'\n",
    "        model.add(Activation('relu'))          \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 第一层是一个对输入预处理的层，将图片0-255减去一个平均数，然后将 rgb->bgr\n",
    "model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "ConvBlock(model,2, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras自带的VGG16模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import backend as K\n",
    "# 我们看下自带的模型是如何的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "tf\n"
     ]
    }
   ],
   "source": [
    "print(K.image_data_format())\n",
    "print(K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_witdth = 150\n",
    "image_height = 150\n",
    "input_shape = (image_witdth, image_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = applications.VGG16(include_top=False,weights='imagenet',input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhuanxu/PycharmProjects/udacity/fast-ai/data/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/' #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'\n",
    "utils_path = current_directory + \"/../utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(featurewise_center=True) #featurewise_center: set input mean to 0 over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gen.mean = np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 150, 150, 3), dtype=float32)\n",
      "Tensor(\"input_1:0\", shape=(?, 150, 150, 3), dtype=float32)\n",
      "Tensor(\"block1_conv1/Relu:0\", shape=(?, 150, 150, 64), dtype=float32)\n",
      "Tensor(\"block1_conv2/Relu:0\", shape=(?, 150, 150, 64), dtype=float32)\n",
      "Tensor(\"block1_pool/MaxPool:0\", shape=(?, 75, 75, 64), dtype=float32)\n",
      "Tensor(\"block2_conv1/Relu:0\", shape=(?, 75, 75, 128), dtype=float32)\n",
      "Tensor(\"block2_conv2/Relu:0\", shape=(?, 75, 75, 128), dtype=float32)\n",
      "Tensor(\"block2_pool/MaxPool:0\", shape=(?, 37, 37, 128), dtype=float32)\n",
      "Tensor(\"block3_conv1/Relu:0\", shape=(?, 37, 37, 256), dtype=float32)\n",
      "Tensor(\"block3_conv2/Relu:0\", shape=(?, 37, 37, 256), dtype=float32)\n",
      "Tensor(\"block3_conv3/Relu:0\", shape=(?, 37, 37, 256), dtype=float32)\n",
      "Tensor(\"block3_pool/MaxPool:0\", shape=(?, 18, 18, 256), dtype=float32)\n",
      "Tensor(\"block4_conv1/Relu:0\", shape=(?, 18, 18, 512), dtype=float32)\n",
      "Tensor(\"block4_conv2/Relu:0\", shape=(?, 18, 18, 512), dtype=float32)\n",
      "Tensor(\"block4_conv3/Relu:0\", shape=(?, 18, 18, 512), dtype=float32)\n",
      "Tensor(\"block4_pool/MaxPool:0\", shape=(?, 9, 9, 512), dtype=float32)\n",
      "Tensor(\"block5_conv1/Relu:0\", shape=(?, 9, 9, 512), dtype=float32)\n",
      "Tensor(\"block5_conv2/Relu:0\", shape=(?, 9, 9, 512), dtype=float32)\n",
      "Tensor(\"block5_conv3/Relu:0\", shape=(?, 9, 9, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg16.layers:\n",
    "    print(layer.input)\n",
    "#     print(layer.input_shape) # channels_last\n",
    "#     print(layer.output_shape) # channels_last\n",
    "# 此处第一第二层干了什么事情？不是很明白呢，看代码中其实就是一个简单的input，没什么特殊处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer.input_shape\n",
    "# layer.output_shape\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = gen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(image_witdth, image_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unknown': 0}\n",
      "50\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(generator.class_indices)\n",
    "print(generator.samples)\n",
    "print(generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 序\n",
    "bottleneck_features_train = vgg16.predict_generator(\n",
    "        generator, steps = generator.samples // generator.batch_size)\n",
    "# 其实这一步就是简单的提取特征，现在我不明白的是Vgg16中前两层是干啥用的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bottleneck_features_train) # 48 // 8 = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
